{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MWPM benchmarks for the toric code with repetitions\n",
    "\n",
    "Here we will run MWPM for two different strategies\n",
    "1. Initialize MWPM with a detector error model (weighted detector error graph) corresponding to $\\beta p$, and evaluate on errors sampled from $p$\n",
    "2. Initialize MWPM with a detector error model (weighted detector error graph) corresponding to $p$, and evaluate on errors sampled from $\\beta p$\n",
    "\n",
    "For us, 1. is more relevant but I'm just curious to see whether 2. gives similar behavior in $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mldec.datasets.reps_toric_code_data import make_sampler\n",
    "from mldec.datasets import reps_toric_code_data\n",
    "from mldec.models import baselines\n",
    "from mldec.utils import evaluation\n",
    "import torch\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# Baseline accuracies: set up pymatching decoder for validation set; do this directly on stim detection events\n",
    "base_config = {\n",
    "    \"repetitions\": 5,\n",
    "    \"code_size\": 3,\n",
    "    \"p\": 0.001,\n",
    "    \"beta\": 1.0,\n",
    "}\n",
    "# create a small validation dataset\n",
    "n_test = int(1e3)\n",
    "\n",
    "\n",
    "def func(beta_seed, base_config=base_config, n_test=n_test):\n",
    "    \"\"\"Initialize MWPM with beta*p, evaluate on errors sampled from p.\"\"\"\n",
    "    beta, seed = beta_seed\n",
    "    data_val, triv_val, stim_data_val, observable_flips_val = reps_toric_code_data.sample_dataset(n_test, base_config, device)\n",
    "    training_config = base_config.copy()\n",
    "    training_config[\"beta\"] = beta\n",
    "    print(training_config)\n",
    "    _, _, detector_error_model = reps_toric_code_data.make_sampler(training_config)\n",
    "    mwpm_decoder = baselines.CyclesMinimumWeightPerfectMatching(detector_error_model)\n",
    "    minimum_weight_correct_nontrivial = evaluation.evaluate_mwpm(stim_data_val, observable_flips_val, mwpm_decoder).item()\n",
    "    minimum_weight_val_acc = (minimum_weight_correct_nontrivial + triv_val) / n_test\n",
    "    return minimum_weight_val_acc\n",
    "\n",
    "def process_beta(beta_seed):\n",
    "    return func(beta_seed, base_config=base_config, n_test=n_test)\n",
    "\n",
    "# generate a list of (beta, seed) for beta in range(1, 15) and seed in range(10)\n",
    "beta_list = range(1, 3)\n",
    "ntrials = 1\n",
    "beta_seed_list = [(beta, 1234+ seed) for beta in beta_list for seed in range(ntrials)]\n",
    "\n",
    "with Pool() as pool:\n",
    "    errors_per_beta = pool.map(process_beta, beta_seed_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'train' a MWPM with the DEM for beta*p\n",
    "data_val, triv_val, stim_data_val, observable_flips_val = reps_toric_code_data.sample_dataset(n_test, base_config, device)\n",
    "\n",
    "training_config = base_config.copy()\n",
    "training_config[\"beta\"] = beta\n",
    "print(training_config)\n",
    "_, _, detector_error_model = reps_toric_code_data.make_sampler(training_config)\n",
    "mwpm_decoder = baselines.CyclesMinimumWeightPerfectMatching(detector_error_model)\n",
    "minimum_weight_correct_nontrivial = evaluation.evaluate_mwpm(stim_data_val, observable_flips_val, mwpm_decoder).item()\n",
    "minimum_weight_val_acc = (minimum_weight_correct_nontrivial + triv_val) / n_test\n",
    "print(\"minweight acc: {}\".format(minimum_weight_val_acc))\n",
    "errors_per_beta.append(minimum_weight_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim, numpy as np\n",
    "dataset_config = {\n",
    "    \"repetitions\": 5,\n",
    "    \"code_size\": 3,\n",
    "    \"p\": 0.001,\n",
    "    \"beta\": 1.0,\n",
    "}\n",
    "repetitions = dataset_config.get(\"repetitions\") # \"cycles\" of measurement\n",
    "code_size = dataset_config.get(\"code_size\")\n",
    "p_base = dataset_config.get(\"p\")\n",
    "beta = dataset_config.get(\"beta\")\n",
    "p = p_base * beta\n",
    "# Initialize stim circuit for a fixed training rate\n",
    "circuit = stim.Circuit.generated(\n",
    "            \"surface_code:rotated_memory_z\",\n",
    "            rounds = repetitions,\n",
    "            distance = code_size,\n",
    "            after_clifford_depolarization = p,\n",
    "            after_reset_flip_probability = 0,\n",
    "            before_measure_flip_probability = 0,\n",
    "            before_round_data_depolarization = 0)\n",
    "# get detector coordinates (same for all error rates):\n",
    "detector_coordinates = circuit.get_detector_coordinates()\n",
    "detector_coordinates = np.array(list(detector_coordinates.values()))\n",
    "# rescale space like coordinates:\n",
    "detector_coordinates[:, : 2] = detector_coordinates[:, : 2] / 2\n",
    "detector_coordinates = detector_coordinates.astype(np.uint8)\n",
    "sampler = circuit.compile_detector_sampler() # CompiledDetectorSampler\n",
    "detector_error_model = circuit.detector_error_model(decompose_errors=True) # DetectorErrorModel\n",
    "# the detector error model converts the underlying error behavior\n",
    "# into an error behavior acting on the detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import stim\n",
    "import pymatching\n",
    "circuit = stim.Circuit.generated(\"surface_code:rotated_memory_x\", \n",
    "                                 distance=5, \n",
    "                                 rounds=5, \n",
    "                                 after_clifford_depolarization=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det_data:\n",
      "[[False  True  True]\n",
      " [ True  True  True]\n",
      " [False  True  True]\n",
      " [ True  True  True]]\n",
      "\n",
      "obs_data:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "err_data:\n",
      "[[False  True]\n",
      " [ True  True]\n",
      " [False  True]\n",
      " [ True  True]]\n"
     ]
    }
   ],
   "source": [
    "import stim\n",
    "\n",
    "dem = stim.DetectorErrorModel('''\n",
    "    error(0.5) D0\n",
    "    error(1) D1 D2 L0\n",
    "''')\n",
    "sampler = dem.compile_sampler()\n",
    "det_data, obs_data, err_data = sampler.sample(\n",
    "    shots=4,\n",
    "    return_errors=True)\n",
    "print(\"det_data:\")\n",
    "print(det_data)\n",
    "print(\"\\nobs_data:\")\n",
    "print(obs_data)\n",
    "print(\"\\nerr_data:\")\n",
    "print(err_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
