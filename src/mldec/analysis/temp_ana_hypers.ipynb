{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7958c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dir = \"./results/toric-code-exp-v4.0\"\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12766a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{dir}/transformer_toric_code_only_good_examples_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2301377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>vs_lookup</th>\n",
       "      <th>vs_minweight</th>\n",
       "      <th>lr</th>\n",
       "      <th>d_model</th>\n",
       "      <th>dropout</th>\n",
       "      <th>num_encoder_layers</th>\n",
       "      <th>num_decoder_layers</th>\n",
       "      <th>nhead</th>\n",
       "      <th>dim_feedforward</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166272</td>\n",
       "      <td>0.963072</td>\n",
       "      <td>-0.011681</td>\n",
       "      <td>-0.035509</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.998559</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.998466</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.998901</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.998407</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>16</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id   epoch  train_loss  train_acc  val_loss   val_acc  vs_lookup  \\\n",
       "0     0.0   120.0    0.000235   1.000000  0.166272  0.963072  -0.011681   \n",
       "1     1.0   450.0    0.002595   0.998643  0.002591  0.998643  -0.000346   \n",
       "2     2.0   380.0    0.001491   0.999084  0.003256  0.998559   0.000244   \n",
       "3     3.0  1110.0    0.000875   0.999512  0.004522  0.998466   0.000429   \n",
       "4     4.0   480.0    0.002749   0.998901  0.004751  0.998407   0.000256   \n",
       "\n",
       "   vs_minweight      lr  d_model  dropout  num_encoder_layers  \\\n",
       "0     -0.035509  0.0020       20     0.10                   3   \n",
       "1      0.000061  0.0010       24     0.10                   1   \n",
       "2     -0.000022  0.0008       20     0.15                   2   \n",
       "3     -0.000115  0.0008       16     0.15                   3   \n",
       "4     -0.000174  0.0030       16     0.10                   3   \n",
       "\n",
       "   num_decoder_layers  nhead  dim_feedforward  batch_size  \n",
       "0                   1      4                4           8  \n",
       "1                   1      4                4        1994  \n",
       "2                   1      4                4        2048  \n",
       "3                   1      2                4         512  \n",
       "4                   1      4                4        1024  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae6e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# target = \"./results/fivequbit-code-v4.0\"\n",
    "\n",
    "# df = pd.read_csv(f\"{target}/transformer_fivequbit_code_only_good_examples_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511f770f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>vs_lookup</th>\n",
       "      <th>vs_minweight</th>\n",
       "      <th>lr</th>\n",
       "      <th>d_model</th>\n",
       "      <th>dropout</th>\n",
       "      <th>num_encoder_layers</th>\n",
       "      <th>num_decoder_layers</th>\n",
       "      <th>nhead</th>\n",
       "      <th>dim_feedforward</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166272</td>\n",
       "      <td>0.963072</td>\n",
       "      <td>-0.011681</td>\n",
       "      <td>-0.035509</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.998559</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.998466</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.998901</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.998407</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>16</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>495.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>0.017488</td>\n",
       "      <td>0.991211</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.998606</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>16</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>496.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>0.017363</td>\n",
       "      <td>0.989014</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.998540</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>497.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035730</td>\n",
       "      <td>0.990822</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>-0.007759</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>24</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662362</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.606241</td>\n",
       "      <td>0.961477</td>\n",
       "      <td>-0.016384</td>\n",
       "      <td>-0.037105</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>499.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0.995224</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>24</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id   epoch  train_loss  train_acc  val_loss   val_acc  vs_lookup  \\\n",
       "0       0.0   120.0    0.000235   1.000000  0.166272  0.963072  -0.011681   \n",
       "1       1.0   450.0    0.002595   0.998643  0.002591  0.998643  -0.000346   \n",
       "2       2.0   380.0    0.001491   0.999084  0.003256  0.998559   0.000244   \n",
       "3       3.0  1110.0    0.000875   0.999512  0.004522  0.998466   0.000429   \n",
       "4       4.0   480.0    0.002749   0.998901  0.004751  0.998407   0.000256   \n",
       "..      ...     ...         ...        ...       ...       ...        ...   \n",
       "491   495.0   890.0    0.017488   0.991211  0.004243  0.998606   0.000423   \n",
       "492   496.0  1960.0    0.017363   0.989014  0.002771  0.998540   0.000101   \n",
       "493   497.0  1450.0    0.000008   1.000000  0.035730  0.990822  -0.001087   \n",
       "494   498.0     0.0    0.662362   0.937500  0.606241  0.961477  -0.016384   \n",
       "495   499.0  1460.0    0.006560   0.995224  0.002062  0.998721  -0.000227   \n",
       "\n",
       "     vs_minweight      lr  d_model  dropout  num_encoder_layers  \\\n",
       "0       -0.035509  0.0020       20     0.10                   3   \n",
       "1        0.000061  0.0010       24     0.10                   1   \n",
       "2       -0.000022  0.0008       20     0.15                   2   \n",
       "3       -0.000115  0.0008       16     0.15                   3   \n",
       "4       -0.000174  0.0030       16     0.10                   3   \n",
       "..            ...     ...      ...      ...                 ...   \n",
       "491      0.000025  0.0020       16     0.10                   3   \n",
       "492     -0.000042  0.0005       24     0.10                   1   \n",
       "493     -0.007759  0.0020       24     0.15                   2   \n",
       "494     -0.037105  0.0008       16     0.15                   2   \n",
       "495      0.000140  0.0030       24     0.15                   1   \n",
       "\n",
       "     num_decoder_layers  nhead  dim_feedforward  batch_size  \n",
       "0                     1      4                4           8  \n",
       "1                     1      4                4        1994  \n",
       "2                     1      4                4        2048  \n",
       "3                     1      2                4         512  \n",
       "4                     1      4                4        1024  \n",
       "..                  ...    ...              ...         ...  \n",
       "491                   1      2                4         128  \n",
       "492                   1      2                4         512  \n",
       "493                   1      4                4           8  \n",
       "494                   1      2                4           8  \n",
       "495                   1      4                8       16384  \n",
       "\n",
       "[496 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eceefa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     job_id   epoch  train_loss  train_acc  val_loss   val_acc  vs_lookup  \\\n",
      "0       0.0   120.0    0.000235   1.000000  0.166272  0.963072  -0.011681   \n",
      "1       1.0   450.0    0.002595   0.998643  0.002591  0.998643  -0.000346   \n",
      "2       2.0   380.0    0.001491   0.999084  0.003256  0.998559   0.000244   \n",
      "3       3.0  1110.0    0.000875   0.999512  0.004522  0.998466   0.000429   \n",
      "4       4.0   480.0    0.002749   0.998901  0.004751  0.998407   0.000256   \n",
      "..      ...     ...         ...        ...       ...       ...        ...   \n",
      "490   494.0  1080.0    0.007083   0.994873  0.002498  0.998677   0.000080   \n",
      "491   495.0   890.0    0.017488   0.991211  0.004243  0.998606   0.000423   \n",
      "492   496.0  1960.0    0.017363   0.989014  0.002771  0.998540   0.000101   \n",
      "493   497.0  1450.0    0.000008   1.000000  0.035730  0.990822  -0.001087   \n",
      "494   498.0     0.0    0.662362   0.937500  0.606241  0.961477  -0.016384   \n",
      "\n",
      "     vs_minweight      lr  d_model  dropout  num_encoder_layers  \\\n",
      "0       -0.035509  0.0020       20     0.10                   3   \n",
      "1        0.000061  0.0010       24     0.10                   1   \n",
      "2       -0.000022  0.0008       20     0.15                   2   \n",
      "3       -0.000115  0.0008       16     0.15                   3   \n",
      "4       -0.000174  0.0030       16     0.10                   3   \n",
      "..            ...     ...      ...      ...                 ...   \n",
      "490      0.000095  0.0008       24     0.15                   3   \n",
      "491      0.000025  0.0020       16     0.10                   3   \n",
      "492     -0.000042  0.0005       24     0.10                   1   \n",
      "493     -0.007759  0.0020       24     0.15                   2   \n",
      "494     -0.037105  0.0008       16     0.15                   2   \n",
      "\n",
      "     num_decoder_layers  nhead  dim_feedforward  batch_size  \n",
      "0                     1      4                4           8  \n",
      "1                     1      4                4        1994  \n",
      "2                     1      4                4        2048  \n",
      "3                     1      2                4         512  \n",
      "4                     1      4                4        1024  \n",
      "..                  ...    ...              ...         ...  \n",
      "490                   1      2                4         512  \n",
      "491                   1      2                4         128  \n",
      "492                   1      2                4         512  \n",
      "493                   1      4                4           8  \n",
      "494                   1      2                4           8  \n",
      "\n",
      "[264 rows x 16 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (2,) and arg 1 with shape (0,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m     fractions\u001b[38;5;241m.\u001b[39mappend(frac)\n\u001b[0;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m---> 25\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43munique_hypers\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfractions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mskyblue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFraction of Models with val_acc = 1 for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhyper\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(hyper)\n",
      "File \u001b[1;32mc:\\Users\\peter\\Desktop\\projects\\mldec\\.venv\\Lib\\site-packages\\matplotlib\\pyplot.py:2439\u001b[0m, in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mbar)\n\u001b[0;32m   2436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbar\u001b[39m(\n\u001b[0;32m   2437\u001b[0m         x, height, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, bottom\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2438\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2441\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peter\\Desktop\\projects\\mldec\\.venv\\Lib\\site-packages\\matplotlib\\__init__.py:1461\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1461\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1463\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1464\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1465\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\peter\\Desktop\\projects\\mldec\\.venv\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:2409\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2407\u001b[0m         yerr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_dx(yerr, y0, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_yunits)\n\u001b[1;32m-> 2409\u001b[0m x, height, width, y, linewidth, hatch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make args iterable too.\u001b[39;49;00m\n\u001b[0;32m   2411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2413\u001b[0m \u001b[38;5;66;03m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\peter\\Desktop\\projects\\mldec\\.venv\\Lib\\site-packages\\numpy\\lib\\stride_tricks.py:540\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(subok, *args)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[0;32m    538\u001b[0m args \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(_m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39msubok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 540\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m shape \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[1;32mc:\\Users\\peter\\Desktop\\projects\\mldec\\.venv\\Lib\\site-packages\\numpy\\lib\\stride_tricks.py:422\u001b[0m, in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03msupplied arrays against each other.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;241m31\u001b[39m):\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (2,) and arg 1 with shape (0,)."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hypers = [\"dim_feedforward\", \"d_model\", \"nhead\", \"num_encoder_layers\", \"num_decoder_layers\", \"lr\"]\n",
    "df.head()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for hyper in hypers:\n",
    "    # get unique hypers \n",
    "    unique_hypers = df[hyper].unique()\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Overlay histograms of val_acc for each unique hyper value on the same plot\n",
    "    for hyper in hypers:\n",
    "        unique_hypers = sorted(df[hyper].unique())\n",
    "        fractions = []\n",
    "        for val in unique_hypers:\n",
    "            subset = df[df[hyper] == val]\n",
    "            print(subset)\n",
    "            break\n",
    "            if len(subset) == 0:\n",
    "                frac = 0\n",
    "            else:\n",
    "                epsilon = 0.001\n",
    "                frac = (abs(subset[\"val_acc\"] - 1) < epsilon).sum() / len(subset)\n",
    "            fractions.append(frac)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.bar([str(v) for v in unique_hypers], fractions, color='skyblue')\n",
    "        plt.title(f\"Fraction of Models with val_acc = 1 for {hyper}\")\n",
    "        plt.xlabel(hyper)\n",
    "        plt.ylabel(\"Fraction with val_acc = 1\")\n",
    "        plt.ylim(0, 1.05)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa673079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
