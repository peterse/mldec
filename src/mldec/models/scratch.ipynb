{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from mldec.models import baselines\n",
    "from mldec.utils import evaluation\n",
    "from mldec.datasets import reps_toric_code_data\n",
    "import stim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # data_val, triv_val, stim_data_val, observable_flips_val = reps_toric_code_data.sample_dataset(n_data, validation_dataset_config, device)\n",
    "    # TIMINGS for repetitions=9:\n",
    "    #  - 1e5 data: 16s\n",
    "    #  - 1e6 data: 160s (2:40)\n",
    "    # TIMINGS for repetitions=3:\n",
    "    #  - 1e5 data: 9s\n",
    "    #  - 1e6 data: 90s (1:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_logical_errors(circuit: stim.Circuit, num_shots: int) -> int:\n",
    "    # Sample the circuit.\n",
    "    sampler = circuit.compile_detector_sampler()\n",
    "    detection_events, observable_flips = sampler.sample(num_shots, separate_observables=True)\n",
    "\n",
    "    # Configure a decoder using the circuit.\n",
    "    detector_error_model = circuit.detector_error_model(decompose_errors=True)\n",
    "    matcher = pymatching.Matching.from_detector_error_model(detector_error_model)\n",
    "\n",
    "    # Run the decoder.\n",
    "    predictions = matcher.decode_batch(detection_events)\n",
    "\n",
    "    # Count the mistakes.\n",
    "    num_errors = 0\n",
    "    for shot in range(num_shots):\n",
    "        actual_for_shot = observable_flips[shot]\n",
    "        predicted_for_shot = predictions[shot]\n",
    "        if not np.array_equal(actual_for_shot, predicted_for_shot):\n",
    "            num_errors += 1\n",
    "    return num_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0093\n",
      "0.01114\n",
      "0.011199\n",
      "0.0113531\n"
     ]
    }
   ],
   "source": [
    "validation_dataset_config = {\n",
    "    'p': 0.004,\n",
    "    'repetitions': 3,\n",
    "    'code_size': 3,\n",
    "    'beta': 1, \n",
    "}\n",
    "for n_test in [1e4, 1e5, 1e6, 1e7]:\n",
    "    circuit = stim.Circuit.generated(\n",
    "            \"surface_code:rotated_memory_z\",\n",
    "            rounds = validation_dataset_config.get(\"repetitions\")   ,\n",
    "            distance = validation_dataset_config.get(\"code_size\"),\n",
    "            after_clifford_depolarization = validation_dataset_config.get(\"p\"),\n",
    "            after_reset_flip_probability = validation_dataset_config.get(\"p\"),\n",
    "            before_measure_flip_probability = validation_dataset_config.get(\"p\"),\n",
    "            before_round_data_depolarization = validation_dataset_config.get(\"p\"))\n",
    "    n_errs = count_logical_errors(circuit, int(n_test))\n",
    "    print(n_errs / n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000.0\n",
      "0.0006\n",
      "[0.0006]\n",
      "100000.0\n",
      "0.00063\n",
      "[0.00063]\n",
      "1000000.0\n",
      "0.00081\n",
      "[0.00081]\n"
     ]
    }
   ],
   "source": [
    "validation_dataset_config = {\n",
    "    'p': 0.001,\n",
    "    'repetitions': 3,\n",
    "    'code_size': 3,\n",
    "    'beta': 1, \n",
    "}\n",
    "device = torch.device(\"cpu\")\n",
    "sampler, detector_coordinates, detector_error_model = reps_toric_code_data.make_sampler(validation_dataset_config)\n",
    "for n_test in [1e4, 1e5, 1e6,]:\n",
    "    print(n_test)\n",
    "    n_test = int(n_test)\n",
    "\n",
    "    # sample detection events and observable flips\n",
    "    stim_data, observable_flips = sampler.sample(shots=n_test, separate_observables=True)\n",
    "    non_empty_indices = (np.sum(stim_data, axis = 1) != 0)\n",
    "    triv_val = len(observable_flips[~ non_empty_indices])\n",
    "    stim_data_val = stim_data[non_empty_indices, :]\n",
    "    observable_flips_val = observable_flips[non_empty_indices]\n",
    "\n",
    "    # Configure a decoder using the circuit.\n",
    "    detector_error_model = circuit.detector_error_model(decompose_errors=True)\n",
    "    matcher = pymatching.Matching.from_detector_error_model(detector_error_model)\n",
    "\n",
    "    # Run the decoder.\n",
    "    predictions = matcher.decode_batch(stim_data_val)\n",
    "\n",
    "    # Count the mistakes.\n",
    "    num_errors = 0\n",
    "    for shot in range(len(stim_data_val)):\n",
    "        actual_for_shot = observable_flips_val[shot]\n",
    "        predicted_for_shot = predictions[shot]\n",
    "        if not np.array_equal(actual_for_shot, predicted_for_shot):\n",
    "            num_errors += 1\n",
    "    print(num_errors / n_test)\n",
    "\n",
    "    mwpm_decoder = baselines.CyclesMinimumWeightPerfectMatching(detector_error_model)\n",
    "    minimum_weight_correct = evaluation.evaluate_mwpm(stim_data_val, observable_flips_val, mwpm_decoder)\n",
    "    print(1 - (minimum_weight_correct + triv_val) / n_test)\n",
    "\n",
    "    # minimum_weight_val_acc = (minimum_weight_val_acc_nontrivial + triv_val) / n_test\n",
    "    # print(\"mwpm logical err rate: {}\".format(1 - minimum_weight_val_acc))\n",
    "    # print(\"nontrivial mwpm err rate: {}\".format(1 - minimum_weight_val_acc_nontrivial / (n_test - triv_val)))\n",
    "    # print()\n",
    "    # print(\"nontrivial mwpm acc: {}\".format(minimum_weight_val_acc_nontrivial / (n_test - triv_val)))\n",
    "    # print(\"mwpm logical acc: {}\".format(minimum_weight_val_acc))\n",
    "    # print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157488"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stim_data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[789]\n",
      "789\n"
     ]
    }
   ],
   "source": [
    "predictions = mwpm_decoder.predict(stim_data_val)\n",
    "print(sum(observable_flips_val != predictions))\n",
    "j = 0\n",
    "for i in range(len(stim_data_val)):\n",
    "    if observable_flips_val[i] != predictions[i]:\n",
    "        j += 1\n",
    "print(j )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mwpm logical err rate: 0.00039999999999995595\n",
      "nontrivial mwpm err rate: 0.00039999999999995595\n",
      "\n",
      "nontrivial mwpm acc: 0.9996\n",
      "mwpm logical acc: 0.9996\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(minimum_weight_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02963425 0.0127577  0.01458658 0.02001265 0.00236165 0.01721928\n",
      " 0.0009453  0.02001873 0.00479258]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(222)\n",
    "p = 0.01\n",
    "var = 0.01\n",
    "n = 9\n",
    "p_samp = np.random.normal(p, var, size=n)\n",
    "print(p_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\Desktop\\projects\\mldec\\src\\mldec\\datasets\\toric_code_data.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Xb_tensor = torch.tensor(X_full, dtype=torch.float32)\n",
      "C:\\Users\\peter\\Desktop\\projects\\mldec\\src\\mldec\\datasets\\toric_code_data.py:186: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Yb_tensor = torch.tensor(Y_full, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from mldec.datasets import toric_code_data\n",
    "# sample virtual XY\n",
    "config = {'n': 9, 'var': 0.03, 'p': 0.05, 'beta': 1.75}\n",
    "X, Y, probs = toric_code_data.create_dataset_training(n, config, cache=True)\n",
    "Xb, Yb, weightsb, histb = toric_code_data.sample_virtual_XY(probs.numpy(), 1994, n, config, cache=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mldec.datasets import toy_problem_data\n",
    "import torch\n",
    "from mldec.utils import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "observable_flips_list = [0.1*np.ones(4)] * 5 + [0.2*np.ones(4)] * 5 + [0.3*np.ones(4)] * 5\n",
    "observable_flips_list = [val for tup in zip(*observable_flips_list) for val in tup]\n",
    "print(observable_flips_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "batch_size = 10000\n",
    "dataset_config = {\n",
    "    'p': 0.15,\n",
    "    'alpha': 0.33,\n",
    "    'pcm': toy_problem_data.repetition_pcm(n),\n",
    "    \"sos_eos\": (0, 0),\n",
    "}\n",
    "X, Y, weights = toy_problem_data.create_dataset_training(n, dataset_config)\n",
    "weights_np = weights.numpy()\n",
    "\n",
    "Xb, Yb, weightsb, downsampled_weights = toy_problem_data.sample_virtual_XY(weights_np, batch_size, n, dataset_config)\n",
    "downsampled_weights_tensor = torch.tensor(downsampled_weights, dtype=torch.float32)\n",
    "\n",
    "Xgood, Ygood, weightsgood = toy_problem_data.uniform_over_good_examples(n, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mldec.models.baselines import RepetitionCodeLookupTable, RepetitionCodeMinimumWeight\n",
    "\n",
    "\n",
    "\n",
    "mld = RepetitionCodeLookupTable(n)\n",
    "mld.train_on_histogram(Xgood, Ygood, weightsgood)\n",
    "\n",
    "minimum_weight_decoder = RepetitionCodeMinimumWeight(n)\n",
    "minimum_weight_decoder.make_decoder(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 7])\n",
      "torch.Size([256, 7]) torch.Size([256, 10]) torch.Size([120, 10])\n"
     ]
    }
   ],
   "source": [
    "print(Xb.shape)\n",
    "print(X.shape, Y.shape, Ypred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = RepetitionCodeLookupTable(n)\n",
    "lookup.train_on_histogram(X, Y, downsampled_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup train: 0.9994999170303345\n",
      "lookup test: 0.9970260858535767\n",
      "minimum weight: 0.997134804725647\n",
      "optimal: 0.9988806843757629\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_acc = evaluation.weighted_accuracy(lookup, X, Y, downsampled_weights_tensor) # training accuracy is evaluated on the same data from this epoch.\n",
    "val_acc = evaluation.weighted_accuracy(lookup, X, Y, weights) # validation accuracy is evaluated on the full dataset\n",
    "opt_val_acc = evaluation.weighted_accuracy(mld, X, Y, weights) # optimal validation accuracy is evaluated on the full dataset\n",
    "minimum_weight_val_acc = evaluation.weighted_accuracy(minimum_weight_decoder, X, Y, weights) # optimal validation accuracy is evaluated on the full dataset\n",
    "print(\"lookup train:\", train_acc)\n",
    "print(\"lookup test:\", val_acc)\n",
    "print(\"minimum weight:\", minimum_weight_val_acc)\n",
    "print(\"optimal:\", opt_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
