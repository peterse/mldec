{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from mldec.models import baselines\n",
    "from mldec.utils import evaluation\n",
    "from mldec.datasets import reps_toric_code_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to sample 100000 shots: 0.014313936233520508\n",
      "time to generate batch: 6.314815998077393\n",
      "time to convert to torch: 2.2159361839294434\n"
     ]
    }
   ],
   "source": [
    "validation_dataset_config = {\n",
    "    'p': 0.004,\n",
    "    'repetitions': 3,\n",
    "    'code_size': 3,\n",
    "    'beta': 1, \n",
    "}\n",
    "device = torch.device(\"cpu\")\n",
    "n_test = 100000\n",
    "\n",
    "data_val, triv_val, stim_data_val, observable_flips_val = reps_toric_code_data.sample_dataset(n_test, validation_dataset_config, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minweight acc: 0.99898\n"
     ]
    }
   ],
   "source": [
    "_, _, detector_error_model = reps_toric_code_data.make_sampler(validation_dataset_config)\n",
    "mwpm_decoder = baselines.CyclesMinimumWeightPerfectMatching(detector_error_model)\n",
    "minimum_weight_val_acc_nontrivial = evaluation.evaluate_mwpm(stim_data_val, observable_flips_val, mwpm_decoder).item()\n",
    "minimum_weight_val_acc = (minimum_weight_val_acc_nontrivial + triv_val) / n_test\n",
    "print(\"minweight acc: {}\".format(minimum_weight_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(minimum_weight_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02963425 0.0127577  0.01458658 0.02001265 0.00236165 0.01721928\n",
      " 0.0009453  0.02001873 0.00479258]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(222)\n",
    "p = 0.01\n",
    "var = 0.01\n",
    "n = 9\n",
    "p_samp = np.random.normal(p, var, size=n)\n",
    "print(p_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\Desktop\\projects\\mldec\\src\\mldec\\datasets\\toric_code_data.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Xb_tensor = torch.tensor(X_full, dtype=torch.float32)\n",
      "C:\\Users\\peter\\Desktop\\projects\\mldec\\src\\mldec\\datasets\\toric_code_data.py:186: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Yb_tensor = torch.tensor(Y_full, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from mldec.datasets import toric_code_data\n",
    "# sample virtual XY\n",
    "config = {'n': 9, 'var': 0.03, 'p': 0.05, 'beta': 1.75}\n",
    "X, Y, probs = toric_code_data.create_dataset_training(n, config, cache=True)\n",
    "Xb, Yb, weightsb, histb = toric_code_data.sample_virtual_XY(probs.numpy(), 1994, n, config, cache=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mldec.datasets import toy_problem_data\n",
    "import torch\n",
    "from mldec.utils import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "observable_flips_list = [0.1*np.ones(4)] * 5 + [0.2*np.ones(4)] * 5 + [0.3*np.ones(4)] * 5\n",
    "observable_flips_list = [val for tup in zip(*observable_flips_list) for val in tup]\n",
    "print(observable_flips_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "batch_size = 10000\n",
    "dataset_config = {\n",
    "    'p': 0.15,\n",
    "    'alpha': 0.33,\n",
    "    'pcm': toy_problem_data.repetition_pcm(n),\n",
    "    \"sos_eos\": (0, 0),\n",
    "}\n",
    "X, Y, weights = toy_problem_data.create_dataset_training(n, dataset_config)\n",
    "weights_np = weights.numpy()\n",
    "\n",
    "Xb, Yb, weightsb, downsampled_weights = toy_problem_data.sample_virtual_XY(weights_np, batch_size, n, dataset_config)\n",
    "downsampled_weights_tensor = torch.tensor(downsampled_weights, dtype=torch.float32)\n",
    "\n",
    "Xgood, Ygood, weightsgood = toy_problem_data.uniform_over_good_examples(n, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mldec.models.baselines import RepetitionCodeLookupTable, RepetitionCodeMinimumWeight\n",
    "\n",
    "\n",
    "\n",
    "mld = RepetitionCodeLookupTable(n)\n",
    "mld.train_on_histogram(Xgood, Ygood, weightsgood)\n",
    "\n",
    "minimum_weight_decoder = RepetitionCodeMinimumWeight(n)\n",
    "minimum_weight_decoder.make_decoder(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 7])\n",
      "torch.Size([256, 7]) torch.Size([256, 10]) torch.Size([120, 10])\n"
     ]
    }
   ],
   "source": [
    "print(Xb.shape)\n",
    "print(X.shape, Y.shape, Ypred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = RepetitionCodeLookupTable(n)\n",
    "lookup.train_on_histogram(X, Y, downsampled_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup train: 0.9994999170303345\n",
      "lookup test: 0.9970260858535767\n",
      "minimum weight: 0.997134804725647\n",
      "optimal: 0.9988806843757629\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_acc = evaluation.weighted_accuracy(lookup, X, Y, downsampled_weights_tensor) # training accuracy is evaluated on the same data from this epoch.\n",
    "val_acc = evaluation.weighted_accuracy(lookup, X, Y, weights) # validation accuracy is evaluated on the full dataset\n",
    "opt_val_acc = evaluation.weighted_accuracy(mld, X, Y, weights) # optimal validation accuracy is evaluated on the full dataset\n",
    "minimum_weight_val_acc = evaluation.weighted_accuracy(minimum_weight_decoder, X, Y, weights) # optimal validation accuracy is evaluated on the full dataset\n",
    "print(\"lookup train:\", train_acc)\n",
    "print(\"lookup test:\", val_acc)\n",
    "print(\"minimum weight:\", minimum_weight_val_acc)\n",
    "print(\"optimal:\", opt_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
