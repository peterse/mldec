import numpy as np
# import numba
import itertools
import stim
from itertools import chain, combinations
from functools import reduce


def powerset(iterable):
    s = list(iterable)
    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))
        

def span(generators, coset_rep=None, incl_identity=True):
    """
    Given a list of generators ``gens``, yields an iterator
    onto the group generated by products of elements from
    ``gens``.
    
    If ``coset_rep`` is specified, returns the coset of the group generated by
    ``gens`` represented by ``coset_rep``.
    """
    
    if coset_rep is None:
        coset_rep = stim.PauliString("")
    
    for prod in powerset(generators):
        if len(prod)>0:
            yield reduce(lambda P, Q: P*Q, prod, coset_rep)
        elif incl_identity:
            yield coset_rep


def independent_bitflip_error_prob(p, pauli):
    # fixem: make this valid for arbitrary n
    x, z = pauli.to_numpy()
    if any(z):
        return 0
    y = x & z
    if any(y):
        return 0
    n = len(x)
    x  = x ^ y
    wt = sum(x)
    return p**wt * (1-p)**(n-wt)

def pauli_vector_channel(p, pauli, n):
    """p is an array [p_I, p_X, p_Y, p_Z]. Make sure it sums to one"""
    x, z = pauli.to_numpy()
    y = x & z
    x = x ^ y
    z = z ^ y
    sx, sy, sz = sum(x), sum(y), sum(z)
    return p[0]**(n-sx-sy-sz) * p[1]**sx * p[2]**sy * p[3]**sz


# @numba.jit(nopython=True, parallel=False) #parallel speeds up computation only over very large matrices
# M is a mxn matrix binary matrix 
# all elements in M should be uint8 
# ripped from https://gist.github.com/popcornell/bc29d1b7ba37d824335ab7b6280f7fec
def gf2elim(M):
    m,n = M.shape
    i=0
    j=0
    while i < m and j < n:
        # find value and index of largest element in remainder of column j
        k = np.argmax(M[i:, j]) +i
        # swap rows
        #M[[k, i]] = M[[i, k]] this doesn't work with numba
        temp = np.copy(M[k])
        M[k] = M[i]
        M[i] = temp
        aijn = M[i, j:]
        col = np.copy(M[:, j]) #make a copy otherwise M will be directly affected
        col[i] = 0 #avoid xoring pivot row with itself
        flip = np.outer(col, aijn)
        M[:, j:] = M[:, j:] ^ flip
        i += 1
        j +=1
    return M


def compute_coset_distribution(generators, logical_paulis, error_p_func):
    
    r = len(generators)
    n = len(generators[0])
    k = n - r
    assert len(logical_paulis) == 2*k
    dtype = np.uint8 #FIXME: doesn't work with bool?

    # construct a symplectic matrix for this code
    symplectic_code = np.concatenate([np.concatenate(g.to_numpy()).reshape(1, -1) for g in generators]).astype(dtype)
    print("code:")
    print(symplectic_code)
    logical_coset_p = np.zeros((2**r, 4**k), dtype=float)

    for i_syndrome, syndrome in enumerate(itertools.product([0, 1], repeat=r)):
            print()
            print(syndrome, "syndrome")
            # 2. Find a representative of the coset of t_i*N(S), where i is the syndrome and t is a pure error
            syndrome_arr = np.array(syndrome, dtype=dtype).reshape(-1, 1)
            augmented = np.concatenate((symplectic_code, syndrome_arr), axis=1)
            sol = gf2elim(augmented)
            padding = np.zeros(n, dtype=bool)
            if np.allclose(sol[:r,:r], np.eye(r)):
                print("1")
                representative_bitstring = np.concatenate([sol[:,-1], np.zeros((k), dtype=dtype)]).astype(bool)
                error_repr_i = stim.PauliString.from_numpy(xs=padding, zs=representative_bitstring)
            else:
                print("2")
                # There are no Z operators with that syndrome. Try again but flip the symplectic structure
                # FIXME: this is a hack; I think it only is an issue for a distance<3 code..
                flipped_code = np.concatenate((symplectic_code[:, n:], symplectic_code[:, :n]), axis=1)
                augmented = np.concatenate((flipped_code, syndrome_arr), axis=1)
                print("before")
                print(sol)
                sol = gf2elim(augmented)
                print("after")
                print(sol)
                representative_bitstring = np.concatenate([sol[:,-1], np.zeros((k), dtype=dtype)]).astype(bool)
                error_repr_i = stim.PauliString.from_numpy(xs=representative_bitstring, zs=padding)

            truth = [1 ^ error_repr_i.commutes(g) for g in generators]
            assert np.allclose(truth, syndrome), f"ERROR: {truth} != {syndrome} (GOT WRONG SYNDROME)"


            # 3. Build the coset t_i * L_j * S and compute its cumulative probability
            # Do so by generating all logical operators from the given Xbar and Zbar operators
            for j_coset, logical_j_prod in enumerate(powerset(logical_paulis)):
                # Compute a logical operator L_j
                if len(logical_j_prod) > 0:
                    logical_j = reduce(lambda P, Q: P*Q, logical_j_prod)
                else:
                    logical_j = stim.PauliString("")
                # Enumerate the coset t_i * L_j * S
                coset_ij = span(generators, coset_rep=error_repr_i *logical_j, incl_identity=True)
                coset_prob = 0
                for op in coset_ij:
                    coset_prob += error_p_func(op)
                logical_coset_p[i_syndrome, j_coset] = coset_prob
                
    return logical_coset_p


def compute_coset_distribution_pure_errors(generators, pure_errors, logical_paulis, error_p_func):
    """Compute the probability distribution over cosets when pure errors are known"""
    r = len(generators)
    n = len(generators[0])
    k = n - r
    print(r, n, k)
    assert len(logical_paulis) == 2*k
    assert len(pure_errors) == r

    # This will store the probability distribution over logical errors
    logical_coset_p = np.zeros((2**r, 4**k), dtype=float)
    ops = []
    for i_syndrome, pure_error_i_prod in enumerate(powerset(pure_errors)):
        # we compute the pure error t_i corresponding to "bitstring" i_syndrome in [0, 2^(n-k))
        if len(pure_error_i_prod) > 0:
            pure_error_i = reduce(lambda P, Q: P*Q, pure_error_i_prod)
        else:
            pure_error_i = stim.PauliString("")

        for j_coset, logical_j_prod in enumerate(powerset(logical_paulis)):
            # Compute a logical operator L_j corresponding to a coset label in [0, 4^k)
            if len(logical_j_prod) > 0:
                logical_j = reduce(lambda P, Q: P*Q, logical_j_prod)
            else:
                logical_j = stim.PauliString("")
            coset_ij = span(generators, coset_rep=pure_error_i *logical_j, incl_identity=True)
            coset_prob = 0
            for op in coset_ij:
                coset_prob += error_p_func(op)
            logical_coset_p[i_syndrome, j_coset] = coset_prob
            for x in coset_ij:
                ops.append(x)
            
    return logical_coset_p

def compute_coset_weight_distribution(generators, pure_errors, logical_paulis, error_p_func):
    """Compute the probability distribution over cosets when pure errors are known"""
    r = len(generators)
    n = len(generators[0])
    k = n - r
    assert len(logical_paulis) == 2*k
    assert len(pure_errors) == r
    out = np.zeros(n+1, dtype=int)
    # This will store the probability distribution over logical errors
    logical_coset_p = np.zeros((2**r, 4**k), dtype=float)
    ops = []
    for i_syndrome, pure_error_i_prod in enumerate(powerset(pure_errors)):
        # we compute the pure error t_i corresponding to "bitstring" i_syndrome in [0, 2^(n-k))
        if len(pure_error_i_prod) > 0:
            pure_error_i = reduce(lambda P, Q: P*Q, pure_error_i_prod)
        else:
            pure_error_i = stim.PauliString("")
        # we will now inspect all of the logical operator cosets, tracking their 
        # weight distribution as we go. At the end, we compute the most likely coset, and 
        # only keep the weight distribution operators in that coset.
        temp = []
        for j_coset, logical_j_prod in enumerate(powerset(logical_paulis)):
            coset_dct = np.zeros(n+1, dtype=int)
            # Compute a logical operator L_j corresponding to a coset label in [0, 4^k)
            if len(logical_j_prod) > 0:
                logical_j = reduce(lambda P, Q: P*Q, logical_j_prod)
            else:
                logical_j = stim.PauliString("")
            coset_ij = span(generators, coset_rep=pure_error_i *logical_j, incl_identity=True)
            coset_prob = 0

            for op in coset_ij:
                coset_prob += error_p_func(op)
                coset_dct[op.weight] += 1
            logical_coset_p[i_syndrome, j_coset] = coset_prob
            for x in coset_ij:
                ops.append(x)
            temp.append(coset_dct)

        j_max_prob = np.argmax(logical_coset_p[i_syndrome])
        print(temp[j_max_prob])
        out += temp[j_max_prob]
            
    out = dict(zip(range(n+1), out))
    return out


def random_code(n, k, canonical=False):
    """Generate a random code with n qubits and k logical qubits.
    The following works:
        1. Construct canonical generators {Z_i} i=1,...,n-k
        2. Construct canoncial logical operators {X_j, Z_j}, j=n-k+1,...,n
        3. Rotate all the generators by a random clifford
    """
    canon_Z = [stim.PauliString(f"Z{i}*I{n-1}") for i in range(n-k)]
    canon_X = [stim.PauliString(f"X{i}*I{n-1}") for i in range(n-k)]
    log_X = [stim.PauliString(f"X{i}*I{n-1}") for i in range(n-k, n)]
    log_Z = [stim.PauliString(f"Z{i}*I{n-1}") for i in range(n-k, n)]
    if canonical:
        cl = lambda x: x
    else:
        cl = stim.Tableau.random(n)
    generators = [cl(g) for g in canon_Z]
    pure_errors = [cl(g) for g in canon_X]
    logical_paulis = [cl(p) for p in log_X + log_Z]
    return generators, pure_errors, logical_paulis


def mle_success_prob(p_SA):
    """Compute the maximum likelihood decoding success probability
    
    Args:
        p_SA: a 2D array of shape (n, m) where n is the number of syndromes
            and m is the number of logical operators. p_SA[i, j] is the probability
            of observing all operators with syndrome i in a coset of S w/r to logical operator j.
    """
    p_S = p_SA.sum(axis=1)
    p_S_pad = p_S[:, None]
    # this replacement technique is safe since wherever p_S is zero,
    # we will not count that row in the output
    p_A_given_S = np.divide(p_SA, p_S_pad, out=np.zeros_like(p_SA), where=p_S_pad!=0)
    max_along_A = p_A_given_S.max(axis=1)
    return np.dot(p_S, max_along_A)
